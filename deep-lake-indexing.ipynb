{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Using cached docx2txt-0.8.tar.gz (2.8 kB)\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/partha/Development/projects/poc/jupyter-notebook/.venv/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-qsxntp1q/docx2txt/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-qsxntp1q/docx2txt/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-prb1fwz3\n",
      "       cwd: /tmp/pip-install-qsxntp1q/docx2txt/\n",
      "  Complete output (6 lines):\n",
      "  usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: setup.py --help [cmd1 cmd2 ...]\n",
      "     or: setup.py --help-commands\n",
      "     or: setup.py cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for docx2txt\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for docx2txt\n",
      "Failed to build docx2txt\n",
      "Installing collected packages: docx2txt\n",
      "    Running setup.py install for docx2txt ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed docx2txt-0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplake_username = \"aerobolt\"\n",
    "dataset = \"moi-faq\"\n",
    "src_doc = \"docs/FAQ-with-Answers-PolicyPal.docx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "documents = []\n",
    "loader = Docx2txtLoader(src_doc)\n",
    "documents.extend(loader.load())\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=100, chunk_size=1000)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 36 embeddings in 1 batches of size 36:: 100%|██████████| 1/1 [00:18<00:00, 18.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://aerobolt/moi-faq', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (36, 1)      str     None   \n",
      " metadata     json      (36, 1)      str     None   \n",
      " embedding  embedding  (36, 1536)  float32   None   \n",
      "    id        text      (36, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=\"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\"\n",
    "os.environ[\"ACTIVELOOP_TOKEN\"]=\"eyJhbGciOiJIUzUxMiIsImlhdCI6MTY5OTU5NjE5NSwiZXhwIjoxNzMzODEwNTY5fQ.eyJpZCI6ImFlcm9ib2x0In0.6V8OwpSPZQ2OxZKrkX_RuFl2_wCZc02uaTETsw7kaql2q8Uoff3HhRC8_0hHjg8Xzt9a4WwBh_0vFWEO4IXUHw\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "db = DeepLake.from_documents(\n",
    "    texts, embeddings, dataset_path=f\"hub://{deeplake_username}/{dataset}\", overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://aerobolt/moi-faq already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake(\n",
    "        dataset_path=f\"hub://{deeplake_username}/{dataset}\",\n",
    "        read_only=True,\n",
    "        embedding_function=OpenAIEmbeddings()\n",
    "    ) \n",
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs[\"distance_metric\"] = \"cos\"\n",
    "retriever.search_kwargs[\"fetch_k\"] = 20\n",
    "retriever.search_kwargs[\"maximal_marginal_relevance\"] = True\n",
    "retriever.search_kwargs[\"k\"] = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
